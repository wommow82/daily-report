import os
import time
import smtplib
from datetime import datetime

import pandas as pd
import numpy as np
import yfinance as yf
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from email.mime_text import MIMEText
from email.mime.multipart import MIMEMultipart


# =========================
# ê³µí†µ ìœ í‹¸
# =========================

def safe_float(val, default=0.0):
    try:
        if val is None:
            return float(default)
        return float(val)
    except Exception:
        return float(default)


def colorize_number(val, text=None):
    """
    ìˆ«ì ê°’ì— ë”°ë¼ ìƒ‰ìƒ span íƒœê·¸ ë°˜í™˜
    - ì–‘ìˆ˜: ì´ˆë¡ìƒ‰
    - ìŒìˆ˜: ë¹¨ê°„ìƒ‰
    - 0 ë˜ëŠ” None: ì›ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ
    """
    if text is None:
        text = str(val)

    if val is None:
        return text

    try:
        val = float(val)
    except Exception:
        return text

    if val > 0:
        color = "#008000"  # green
    elif val < 0:
        color = "#cc0000"  # red
    else:
        return text

    return f'<span style="color:{color}">{text}</span>'


import os

# =========================
# í—¬í¼ í•¨ìˆ˜ (ìš”ì•½)
# =========================

import json
from datetime import datetime, timedelta

def _short_ko_summary_15(text):
    """
    ì£¼ì–´ì§„ ì˜ì–´ ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ 15ì ë‚´ì™¸ë¡œ ì•„ì£¼ ì§§ê²Œ ìš”ì•½.

    - OPENAI_API_KEY í•„ìš”
    - ì—ëŸ¬ë‚˜ í‚¤ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¬¸êµ¬ ë°˜í™˜
    """
    text = (text or "").strip()
    if not text:
        return "ìš”ì•½ë¶ˆê°€"

    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return "ìš”ì•½ë¶ˆê°€"

    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)

        prompt = (
            "ë‹¤ìŒ ë‰´ìŠ¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì£¼ê°€ì— ì¤‘ìš”í•œ í•µì‹¬ë§Œ "
            "í•œêµ­ì–´ 15ì ì´ë‚´ë¡œ ì•„ì£¼ ì§§ê²Œ ìš”ì•½í•´ì¤˜.\n"
            "ë¬¸ì¥ 1ê°œ, ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ìµœì†Œí™”:\n\n"
            f"{text}"
        )

        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=50,
        )
        summary = (resp.choices[0].message.content or "").strip()
        summary = summary.replace("\n", " ").strip()
        return summary[:15] if summary else "ìš”ì•½ì‹¤íŒ¨"
    except Exception as e:
        print(f"[WARN] _short_ko_summary_15 ì˜¤ë¥˜: {e}")
        return "ìš”ì•½ì‹¤íŒ¨"


def _classify_news_sentiment_and_pick_reps(ticker, articles):
    """
    ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ê¸ì •/ë¶€ì • ê°ì„±ì„ ë¶„ë¥˜í•˜ê³ ,
    ê° ê·¸ë£¹ì—ì„œ 'ëŒ€í‘œ ê¸°ì‚¬ ìµœëŒ€ 2ê°œ'ë¥¼ ê³¨ë¼ 15ì ìš”ì•½ì„ ë§Œë“ ë‹¤.

    ì…ë ¥:
        ticker   : ì¢…ëª© í‹°ì»¤ (ì˜ˆ: "TSLA")
        articles : _fetch_news_for_ticker_midterm ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
                   ê° ì›ì†ŒëŠ” {title, description, source, published} í˜•íƒœ ê°€ì •

    ë°˜í™˜:
        {
          "pos_count": int,             # ê¸ì • ë‰´ìŠ¤ ìˆ˜
          "neg_count": int,             # ë¶€ì • ë‰´ìŠ¤ ìˆ˜
          "pos_repr": str or None,      # ê¸ì • ëŒ€í‘œ: Aìš”ì•½ | Bìš”ì•½
          "neg_repr": str or None,      # ë¶€ì • ëŒ€í‘œ: Cìš”ì•½ | Dìš”ì•½
        }
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key or not articles:
        return {
            "pos_count": 0,
            "neg_count": 0,
            "pos_repr": None,
            "neg_repr": None,
        }

    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
    except Exception as e:
        print(f"[WARN] _classify_news_sentiment_and_pick_reps import ì˜¤ë¥˜: {e}")
        return {
            "pos_count": 0,
            "neg_count": 0,
            "pos_repr": None,
            "neg_repr": None,
        }

    # 1) ë²ˆí˜¸ë¥¼ ë¶™ì—¬ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    items = []
    for i, a in enumerate(articles, start=1):
        title = (a.get("title") or "").strip()
        desc = (a.get("description") or "").strip()
        src = (a.get("source") or "").strip()
        date = a.get("published") or ""
        item = f"[{i}] {date} {src} - {title}"
        if desc:
            item += f"\n{desc}"
        items.append(item)

    bundle_text = "\n\n".join(items)

    prompt = f"""
ë„ˆëŠ” ë¯¸êµ­ ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ì´ë‹¤.
ì•„ë˜ëŠ” {ticker} ê´€ë ¨ ë‰´ìŠ¤ ëª©ë¡ì´ë‹¤.

ê° ë‰´ìŠ¤ê°€ ì£¼ê°€ì— ë¯¸ì¹˜ëŠ” ë°©í–¥ì„±ì„
'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë¶„ë¥˜í•´ë¼.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ë¼. ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
{{
  "items": [
    {{"index": 1, "sentiment": "ê¸ì •"}},
    {{"index": 2, "sentiment": "ë¶€ì •"}},
    {{"index": 3, "sentiment": "ì¤‘ë¦½"}}
  ]
}}

ë‰´ìŠ¤ ëª©ë¡:
{bundle_text}
"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=400,
            response_format={"type": "json_object"},
        )
        raw = resp.choices[0].message.content
        data = json.loads(raw)
        items_sent = data.get("items", [])
    except Exception as e:
        print(f"[WARN] ê°ì„± ë¶„ë¥˜ ì‹¤íŒ¨, ëª¨ë‘ ì¤‘ë¦½ ì²˜ë¦¬: {e}")
        items_sent = []

    # 2) ë¶„ë¥˜ ê²°ê³¼ ì§‘ê³„
    pos_idx = set()
    neg_idx = set()

    for x in items_sent:
        try:
            idx = int(x.get("index"))
            sent = (x.get("sentiment") or "").strip()
        except Exception:
            continue
        if sent == "ê¸ì •":
            pos_idx.add(idx)
        elif sent == "ë¶€ì •":
            neg_idx.add(idx)

    pos_count = len(pos_idx)
    neg_count = len(neg_idx)

    # 3) ëŒ€í‘œ ì¸ë±ìŠ¤ (ìµœì‹ ìˆœì´ë¼ê³  ê°€ì •í•˜ê³  ì‘ì€ index ìš°ì„ )
    pos_sorted = sorted(pos_idx)
    neg_sorted = sorted(neg_idx)

    def _build_repr(indices):
        if not indices:
            return None
        chosen = list(indices)[:2]  # ìµœëŒ€ 2ê°œ
        summaries = []
        for i in chosen:
            if 1 <= i <= len(articles):
                art = articles[i - 1]
                text = (art.get("title") or "") + "\n" + (art.get("description") or "")
                summaries.append(_short_ko_summary_15(text))
        if not summaries:
            return None
        if len(summaries) == 1:
            return summaries[0]
        return f"{summaries[0]} | {summaries[1]}"

    pos_repr = _build_repr(pos_sorted)
    neg_repr = _build_repr(neg_sorted)

    return {
        "pos_count": pos_count,
        "neg_count": neg_count,
        "pos_repr": pos_repr,
        "neg_repr": neg_repr,
    }


def _fetch_news_for_ticker_midterm(ticker, api_key, page_size=3, days=7):
    """
    ì¢…ëª© ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì¤‘ê¸° ë¶„ì„ìš©):
    - 1ìˆœìœ„: NewsAPI
    - 2ìˆœìœ„: Google News RSS fallback

    Returns:
        list of dict: [{title, url, source, published}, ...]
    """
    from datetime import datetime, timedelta
    import requests
    import feedparser

    articles = []

    # 1ï¸âƒ£ NewsAPI ì‹œë„
    try:
        url = "https://newsapi.org/v2/everything"
        params = {
            "q": ticker,
            "apiKey": api_key,
            "language": "en",
            "sortBy": "publishedAt",
            "pageSize": page_size,
            "from": (datetime.today() - timedelta(days=days)).strftime("%Y-%m-%d"),
        }
        r = requests.get(url, params=params, timeout=20)
        if r.status_code == 200:
            data = r.json()
            for a in data.get("articles", []):
                articles.append({
                    "title": a.get("title"),
                    "url": a.get("url"),
                    "source": a.get("source", {}).get("name", ""),
                    "published": a.get("publishedAt", "")[:10],
                    "description": a.get("description", ""),
                })
    except Exception as e:
        print(f"âš ï¸ NewsAPI ì˜¤ë¥˜(midterm): {e}")

    # 2ï¸âƒ£ fallback â†’ Google News RSS
    if not articles:
        try:
            rss_url = (
                f"https://news.google.com/rss/search?"
                f"q={ticker}+stock&hl=en&gl=US&ceid=US:en"
            )
            feed = feedparser.parse(rss_url)
            for entry in feed.entries[:page_size]:
                src = "Google News"
                if hasattr(entry, "source") and getattr(entry, "source"):
                    try:
                        src = getattr(entry, "source").get("title", "Google News")
                    except Exception:
                        src = "Google News"

                published = ""
                if hasattr(entry, "published"):
                    published = entry.published[:16]

                articles.append({
                    "title": entry.title,
                    "url": entry.link,
                    "source": src,
                    "published": published,
                    "description": getattr(entry, "summary", ""),
                })
        except Exception as e:
            print(f"âš ï¸ Google News RSS ì˜¤ë¥˜(midterm): {e}")

    return articles


# =========================
# NewsAPI/RSS ê¸°ë°˜ ì¢…ëª© ë‰´ìŠ¤ â†’ ì£¼ê°€ ì˜í–¥ ì¤‘ì‹¬ ìš”ì•½ â†’ HTML
# =========================

def build_midterm_news_comment_from_apis_combined(ticker, max_items=10, days=30):
    """
    ì¤‘ê¸° ë¶„ì„ ì„¹ì…˜ì—ì„œ ì‚¬ìš©í•  'ìµœê·¼ 1ê°œì›” ë‰´ìŠ¤ ìš”ì•½' HTML ìƒì„±.

    - ì¡°íšŒ ê¸°ê°„: ê¸°ë³¸ ìµœê·¼ 30ì¼ (1ê°œì›”)
    - ì†ŒìŠ¤: NewsAPI â†’ ì‹¤íŒ¨ ì‹œ Google News RSS
    - ìµœëŒ€ max_itemsê°œ ê¸°ì‚¬ ì‚¬ìš©
    - í‹°ì»¤/íšŒì‚¬ëª… í¬í•¨ ì—¬ë¶€ë¡œ 1ì°¨ í•„í„°ë§
    - ê¸°ì‚¬ë“¤ì„ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
    - OpenAIë¡œ ê¸ì •/ë¶€ì • ê°ì„± ë¶„ë¥˜
    - ê¸ì •/ë¶€ì • ë‰´ìŠ¤ ê°¯ìˆ˜ í‘œì‹œ
    - ê¸ì •/ë¶€ì • ê°ê° ëŒ€í‘œ ë‰´ìŠ¤ ìµœëŒ€ 2ê°œë¥¼ ë½‘ì•„
      15ì ë‚´ì™¸ í•œê¸€ ìš”ì•½ì„ "Aìš”ì•½ | Bìš”ì•½" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
      Â· ê¸ì •: ì´ˆë¡ìƒ‰
      Â· ë¶€ì •: ë¹¨ê°„ìƒ‰

    ë°˜í™˜:
        HTML ë¬¸ìì—´ (<p> ... </p>)
    """
    api_key = os.environ.get("NEWS_API_KEY")
    if not api_key:
        return (
            "<p style='text-align:left;'>"
            "<strong>ë‰´ìŠ¤ ìš”ì•½ (ìµœê·¼ 1ê°œì›”):</strong><br>"
            "- NEWS_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì•„ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            "</p>"
        )

    # 1) NewsAPI + Google Newsë¡œ ê¸°ì‚¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ìµœê·¼ daysì¼ ê¸°ì¤€)
    articles = _fetch_news_for_ticker_midterm(
        ticker=ticker,
        api_key=api_key,
        page_size=max_items,
        days=days,
    )

    if not articles:
        return (
            "<p style='text-align:left;'>"
            "<strong>ë‰´ìŠ¤ ìš”ì•½ (ìµœê·¼ 1ê°œì›”):</strong><br>"
            f"- ìµœê·¼ {days}ì¼ ë‚´ {ticker} ê´€ë ¨ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            "</p>"
        )

    # 1-1) ì‹¤ì œ ë‚ ì§œ ê¸°ì¤€ ìµœê·¼ 30ì¼ë§Œ ì¶”ê°€ í•„í„°ë§
    cutoff = datetime.utcnow() - timedelta(days=30)
    filtered_recent = []
    for a in articles:
        p = (a.get("published") or "").strip()
        dt = None
        for fmt in ("%Y-%m-%dT%H:%M:%SZ", "%Y-%m-%d %H:%M", "%Y-%m-%d"):
            try:
                dt = datetime.strptime(p[:len(fmt)], fmt)
                break
            except Exception:
                continue
        if dt is None:
            filtered_recent.append(a)
        else:
            if dt >= cutoff:
                filtered_recent.append(a)

    if not filtered_recent:
        return (
            "<p style='text-align:left;'>"
            "<strong>ë‰´ìŠ¤ ìš”ì•½ (ìµœê·¼ 1ê°œì›”):</strong><br>"
            f"- ìµœê·¼ 30ì¼ ë‚´ {ticker} ê´€ë ¨ ìœ íš¨í•œ ë‚ ì§œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            "</p>"
        )

    articles = filtered_recent

    # 2) í‹°ì»¤/íšŒì‚¬ëª… ê¸°ì¤€ìœ¼ë¡œ ê´€ë ¨ ê¸°ì‚¬ í•„í„°ë§
    ticker_upper = ticker.upper()
    keywords = [ticker_upper]

    company_map = {
        "NVDA": "NVIDIA",
        "TSLA": "TESLA",
        "SCHD": "SCHD",
    }
    if ticker_upper in company_map:
        keywords.append(company_map[ticker_upper].upper())

    filtered = []
    for a in articles:
        text_all = (
            (a.get("title") or "") + " " + (a.get("description") or "")
        ).upper()
        if any(k in text_all for k in keywords):
            filtered.append(a)

    # í•„í„°ë§ ê²°ê³¼ê°€ ë„ˆë¬´ ì ìœ¼ë©´, ì›ë³¸ ë¦¬ìŠ¤íŠ¸ë„ ì¼ë¶€ ì‚¬ìš©
    if len(filtered) >= 3:
        use_articles = filtered[:max_items]
    else:
        use_articles = articles[:max_items]

    # 2-1) ìµœì‹  ë‰´ìŠ¤ ìš°ì„  ì •ë ¬ (published ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
    def _parse_dt(a):
        p = (a.get("published") or "").strip()
        for fmt in ("%Y-%m-%dT%H:%M:%SZ", "%Y-%m-%d %H:%M", "%Y-%m-%d"):
            try:
                return datetime.strptime(p[:len(fmt)], fmt)
            except Exception:
                continue
        return datetime.min

    use_articles = sorted(use_articles, key=_parse_dt, reverse=True)

    # 3) ê¸ì •/ë¶€ì • ë¶„ë¥˜ ë° ëŒ€í‘œ ë‰´ìŠ¤ ì„ ë³„ + 15ì ìš”ì•½(ìµœëŒ€ 2ê°œì”©, "A | B" í˜•ì‹)
    sent_info = _classify_news_sentiment_and_pick_reps(ticker, use_articles)
    pos_count = sent_info["pos_count"]
    neg_count = sent_info["neg_count"]
    pos_repr = sent_info["pos_repr"]
    neg_repr = sent_info["neg_repr"]

    # 4) HTML êµ¬ì„± (ìƒ‰ìƒ ê°•ì¡°)
    lines = []
    lines.append(
        f"<span style='color:green;'>ê¸ì • ë‰´ìŠ¤ {pos_count}ê±´</span>, "
        f"<span style='color:red;'>ë¶€ì • ë‰´ìŠ¤ {neg_count}ê±´</span>"
    )

    if pos_repr:
        lines.append(
            f"<span style='color:green;'>Â· ëŒ€í‘œ ê¸ì •: {pos_repr}</span>"
        )
    if neg_repr:
        lines.append(
            f"<span style='color:red;'>Â· ëŒ€í‘œ ë¶€ì •: {neg_repr}</span>"
        )

    html_body = "<br>".join(lines)

    html = (
        "<p style='text-align:left;'>"
        "<strong>ë‰´ìŠ¤ ìš”ì•½ (ìµœê·¼ 1ê°œì›”, ì£¼ê°€ ì˜í–¥ ì´ìŠˆ):</strong><br>"
        f"{html_body}"
        "</p>"
    )
    return html


# =========================
# Google Sheets í´ë¼ì´ì–¸íŠ¸
# =========================

def get_gspread_client():
    json_keyfile = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if not json_keyfile:
        raise EnvironmentError(
            "í™˜ê²½ë³€ìˆ˜ GOOGLE_APPLICATION_CREDENTIALS ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        )

    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile, scope)
    return gspread.authorize(creds)


def open_gsheet(gs_id, retries=3, delay=5):
    if not gs_id:
        raise EnvironmentError("í™˜ê²½ë³€ìˆ˜ GSHEET_ID ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    client = get_gspread_client()
    for i in range(retries):
        try:
            return client.open_by_key(gs_id)
        except gspread.exceptions.APIError as e:
            if "503" in str(e) and i < retries - 1:
                print(
                    f"âš ï¸ Google API 503 ì˜¤ë¥˜ ë°œìƒ, {delay}ì´ˆ í›„ ì¬ì‹œë„... "
                    f"({i + 1}/{retries})"
                )
                time.sleep(delay)
                continue
            raise


# =========================
# ì‹œì„¸ / í™˜ìœ¨ ìœ í‹¸
# =========================

def get_last_and_prev_close(ticker, period="2y"):
    try:
        hist = yf.Ticker(ticker).history(period=period)
        if len(hist) < 2:
            return None, None

        last = hist["Close"].iloc[-1]
        prev = hist["Close"].iloc[-2]
        return float(last), float(prev)
    except Exception:
        return None, None


def get_fx_rate_usdcad():
    try:
        fx = yf.Ticker("CAD=X").history(period="2d")
        if fx.empty:
            return None
        return float(fx["Close"].iloc[-1])
    except Exception:
        return None


# =========================
# í¬íŠ¸í´ë¦¬ì˜¤/ì‹œíŠ¸ ë¡œë”©
# =========================

def load_holdings_from_gsheet(sheet):
    """
    Google Sheetì—ì„œ Holdings íƒ­ì„ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜.
    """
    try:
        ws = sheet.worksheet("Holdings")
    except gspread.WorksheetNotFound:
        raise RuntimeError("Holdings ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    data = ws.get_all_records()
    df = pd.DataFrame(data)
    return df


def load_settings_from_gsheet(sheet):
    """
    Settings íƒ­ì—ì„œ ê³„ì •ë³„ ì„¤ì •ê°’(ì˜ˆ: NetDeposit, ëª©í‘œì¹˜ ë“±)ì„ ì½ì–´ì˜¨ë‹¤.
    """
    try:
        ws = sheet.worksheet("Settings")
    except gspread.WorksheetNotFound:
        raise RuntimeError("Settings ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    data = ws.get_all_records()
    df = pd.DataFrame(data)
    return df


# =========================
# HTML ë¹Œë” (ë³´ìœ  ì¢…ëª©/ê³„ì¢Œ ìš”ì•½ ë“±)
# =========================

def build_holdings_table_html(df_holdings, account_name="TFSA"):
    """
    ë³´ìœ  ì¢…ëª© í…Œì´ë¸”ì„ HTMLë¡œ ìƒì„±.
    df_holdings: í•´ë‹¹ ê³„ì¢Œ(TFSA/RESP)ë§Œ í•„í„°ë§ëœ DataFrame
    """
    if df_holdings.empty:
        return f"<p>{account_name} ê³„ì¢Œì˜ ë³´ìœ  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.</p>"

    cols = ["Ticker", "Name", "Currency", "Shares", "AvgPrice", "MarketPrice", "MarketValue", "GainLoss", "GainLossPct"]
    df = df_holdings.copy()
    for c in cols:
        if c not in df.columns:
            df[c] = ""

    df["MarketValue"] = df["MarketValue"].apply(lambda x: float(x) if x not in [None, ""] else 0.0)
    df["GainLoss"] = df["GainLoss"].apply(lambda x: float(x) if x not in [None, ""] else 0.0)
    df["GainLossPct"] = df["GainLossPct"].apply(lambda x: float(x) if x not in [None, ""] else 0.0)

    headers = [
        "Ticker",
        "ì¢…ëª©ëª…",
        "í†µí™”",
        "ë³´ìœ ì£¼ì‹",
        "í‰ë‹¨ê°€",
        "í˜„ì¬ê°€",
        "í‰ê°€ê¸ˆì•¡",
        "ì†ìµ",
        "ì†ìµë¥ ",
    ]
    html = [
        f"<h3>{account_name} ë³´ìœ  ì¢…ëª©</h3>",
        "<table border='1' cellspacing='0' cellpadding='4' style='border-collapse:collapse;'>",
        "<thead><tr>",
    ]
    for h in headers:
        html.append(f"<th>{h}</th>")
    html.append("</tr></thead><tbody>")

    for _, row in df.iterrows():
        gain = row["GainLoss"]
        gain_pct = row["GainLossPct"]
        gain_html = colorize_number(gain, f"{gain:,.2f}")
        gain_pct_html = colorize_number(gain_pct, f"{gain_pct:.2f}%")

        html.append("<tr>")
        html.append(f"<td>{row['Ticker']}</td>")
        html.append(f"<td>{row['Name']}</td>")
        html.append(f"<td>{row['Currency']}</td>")
        html.append(f"<td>{row['Shares']}</td>")
        html.append(f"<td>{row['AvgPrice']}</td>")
        html.append(f"<td>{row['MarketPrice']}</td>")
        html.append(f"<td>{row['MarketValue']:,.2f}</td>")
        html.append(f"<td>{gain_html}</td>")
        html.append(f"<td>{gain_pct_html}</td>")
        html.append("</tr>")

    html.append("</tbody></table>")
    return "".join(html)


def build_account_summary_html(df_holdings, fx_usdcad):
    """
    ì „ì²´ ê³„ì¢Œ(TFSA + RESP)ì˜ í‰ê°€ê¸ˆì•¡ ë° ì†ìµ ìš”ì•½ HTML.
    """
    if df_holdings.empty:
        return "<p>ë³´ìœ  ì¢…ëª© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.</p>"

    df = df_holdings.copy()
    for col in ["MarketValue", "GainLoss"]:
        if col not in df.columns:
            df[col] = 0.0
        df[col] = df[col].apply(lambda x: float(x) if x not in [None, ""] else 0.0)

    total_mv_usd = df[df["Currency"] == "USD"]["MarketValue"].sum()
    total_mv_cad = df[df["Currency"] == "CAD"]["MarketValue"].sum()
    total_gain_usd = df[df["Currency"] == "USD"]["GainLoss"].sum()
    total_gain_cad = df[df["Currency"] == "CAD"]["GainLoss"].sum()

    if fx_usdcad:
        total_mv_usd_in_cad = total_mv_usd * fx_usdcad
        total_gain_usd_in_cad = total_gain_usd * fx_usdcad
    else:
        total_mv_usd_in_cad = None
        total_gain_usd_in_cad = None

    total_mv_cad_all = total_mv_cad + (total_mv_usd_in_cad or 0.0)
    total_gain_cad_all = total_gain_cad + (total_gain_usd_in_cad or 0.0)

    gain_html = colorize_number(total_gain_cad_all, f"{total_gain_cad_all:,.2f} CAD")

    html = [
        "<h3>ì „ì²´ ê³„ì¢Œ ìš”ì•½ (TFSA + RESP)</h3>",
        "<ul>",
        f"<li>ì´ í‰ê°€ê¸ˆì•¡ (CAD í™˜ì‚°): {total_mv_cad_all:,.2f} CAD</li>",
        f"<li>ì´ ì†ìµ (CAD í™˜ì‚°): {gain_html}</li>",
        "</ul>",
    ]
    return "".join(html)


# =========================
# Mid-term (6~12ê°œì›”) ë¶„ì„ ì„¹ì…˜
# =========================

def analyze_midterm_ticker(ticker):
    """
    ê°œë³„ ì¢…ëª©ì— ëŒ€í•œ 6~12ê°œì›” ì¤‘ê¸° ë¶„ì„ HTML ìƒì„±.

    - yfinanceë¡œ ê°€ê²©/ë³€ë™ì„± ë“± ì§€í‘œ ìˆ˜ì§‘
    - build_midterm_news_comment_from_apis_combined() ì‚¬ìš©
    """
    try:
        data = yf.Ticker(ticker)
        hist = data.history(period="1y")
        if hist.empty:
            return f"<p>{ticker}: ìµœê·¼ 1ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.</p>"

        last_price = hist["Close"].iloc[-1]
        start_price = hist["Close"].iloc[0]
        ret_1y = (last_price / start_price - 1.0) * 100.0

        # ë‹¨ìˆœ ì—° ë³€ë™ì„± (ì¼ê°„ ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨ Ã— sqrt(252))
        daily_ret = hist["Close"].pct_change().dropna()
        vol_annual = daily_ret.std() * np.sqrt(252) * 100.0

        try:
            fwd_pe = data.info.get("forwardPE", None)
        except Exception:
            fwd_pe = None

        pe_text = f"{fwd_pe:.1f}ë°°" if fwd_pe not in [None, 0] else "N/A"

        if ret_1y > 30:
            ret_comment = "ê°•í•œ ìƒìŠ¹ ì¶”ì„¸ êµ¬ê°„"
        elif ret_1y > 0:
            ret_comment = "ì™„ë§Œí•œ ìƒìŠ¹ ì¶”ì„¸"
        elif ret_1y > -20:
            ret_comment = "ë³´í•©~ì¡°ì • êµ¬ê°„"
        else:
            ret_comment = "ëšœë ·í•œ í•˜ë½ ì¶”ì„¸"

        if vol_annual > 60:
            vol_comment = "ë§¤ìš° ë†’ì€ ë³€ë™ì„±"
        elif vol_annual > 30:
            vol_comment = "ì¤‘ê°„ ìˆ˜ì¤€ ë³€ë™ì„±"
        else:
            vol_comment = "ë¹„êµì  ì•ˆì •ì  ë³€ë™ì„±"

        if fwd_pe and fwd_pe > 60:
            val_comment = "ë°¸ë¥˜ì—ì´ì…˜ ë¶€ë‹´ êµ¬ê°„ ê°€ëŠ¥ì„±"
        elif fwd_pe and fwd_pe > 25:
            val_comment = "ì„±ì¥ì£¼ í”„ë¦¬ë¯¸ì—„ êµ¬ê°„"
        elif fwd_pe:
            val_comment = "ìƒëŒ€ì ìœ¼ë¡œ í•©ë¦¬ì ì¸ ë°¸ë¥˜ì—ì´ì…˜"
        else:
            val_comment = "ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´ ë¶€ì¡±"

        rows = []
        rows.append(
            (
                "1ë…„ ìˆ˜ìµë¥ ",
                f"{ret_1y:+.1f}%",
                f"ìµœê·¼ 1ë…„ê°„ ì¢…ê°€ ê¸°ì¤€ ì£¼ê°€ ìˆ˜ìµë¥  â€“ {ret_comment}",
            )
        )
        rows.append(
            (
                "ì—° ë³€ë™ì„±",
                f"{vol_annual:.1f}%",
                f"ì—° í™˜ì‚° ê°€ê²© ë“±ë½ í­ â€“ {vol_comment}",
            )
        )
        rows.append(
            (
                "Fwd PER",
                pe_text,
                f"í–¥í›„ 1ë…„ ì˜ˆìƒ ì´ìµ ëŒ€ë¹„ í˜„ì¬ ì£¼ê°€ ë°°ìˆ˜ â€“ {val_comment}",
            )
        )

        html_parts = []
        html_parts.append(f"<h3>ğŸ“Š {ticker} 6~12ê°œì›” ì¤‘ê¸° ì§€í‘œ ìš”ì•½</h3>")
        html_parts.append(
            "<table border='1' cellspacing='0' cellpadding='4' "
            "style='border-collapse:collapse;'>"
        )
        html_parts.append("<thead><tr><th>ì§€í‘œ</th><th>ê°’</th><th>í•´ì„</th></tr></thead><tbody>")

        for name, val, desc in rows:
            html_parts.append("<tr>")
            html_parts.append(f"<td>{name}</td>")
            html_parts.append(f"<td>{val}</td>")
            html_parts.append(f"<td>{desc}</td>")
            html_parts.append("</tr>")

        html_parts.append("</tbody></table>")

        comment_html = build_midterm_news_comment_from_apis_combined(ticker)
        html_parts.append(comment_html)

        return "".join(html_parts)

    except Exception as e:
        return f"<p>{ticker} ì¤‘ê¸° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}</p>"


# =========================
# HTML ë¦¬í¬íŠ¸ ì „ì²´ ë¹Œë”
# =========================

def build_html_report(df_holdings, settings_df, fx_usdcad):
    """
    ì´ë©”ì¼ë¡œ ë³´ë‚¼ ì „ì²´ HTML ë¦¬í¬íŠ¸ ìƒì„±.
    - Holdingsë¥¼ TFSA / RESPë¡œ ë‚˜ëˆ„ì–´ í…Œì´ë¸” ìƒì„±
    - ê³„ì¢Œ ìš”ì•½
    - Mid-term Investment Analysis (NVDA, TSLA ë“±)
    """
    html = []
    html.append("<html><body>")
    html.append(f"<h2>ğŸ“ˆ Daily Portfolio Report ({datetime.now().strftime('%Y-%m-%d')})</h2>")

    html.append("<hr>")
    html.append("<h2>ğŸ“Œ ì „ì²´ ê³„ì¢Œ ìš”ì•½</h2>")
    html.append(build_account_summary_html(df_holdings, fx_usdcad))

    html.append("<hr>")
    html.append("<h2>ğŸ“‚ ê³„ì¢Œë³„ ë³´ìœ  ì¢…ëª©</h2>")

    if "Account" in df_holdings.columns:
        tfsa_df = df_holdings[df_holdings["Account"] == "TFSA"]
        resp_df = df_holdings[df_holdings["Account"] == "RESP"]
    else:
        tfsa_df = df_holdings.copy()
        resp_df = df_holdings.iloc[0:0].copy()

    html.append(build_holdings_table_html(tfsa_df, "TFSA"))
    html.append("<br>")
    html.append(build_holdings_table_html(resp_df, "RESP"))

    html.append("<hr>")
    html.append("<h2>ğŸ“ˆ Mid-term Investment Analysis (6~12ê°œì›”)</h2>")
    html.append("<p style='font-size:12px;color:#555;'>"
                "â€» ì˜ˆì‹œ: NVDA, TSLAì— ëŒ€í•´ 6~12ê°œì›” ê´€ì ì˜ ì§€í‘œ/ë‰´ìŠ¤ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤."
                "</p>")

    for ticker in ["NVDA", "TSLA"]:
        html.append("<hr>")
        html.append(analyze_midterm_ticker(ticker))

    html.append("</body></html>")
    return "".join(html)


# =========================
# ì´ë©”ì¼ ì „ì†¡
# =========================

def send_email_report(html_body):
    """
    SMTPë¥¼ ì´ìš©í•´ HTML ë¦¬í¬íŠ¸ ë©”ì¼ ë°œì†¡
    """
    smtp_host = os.environ.get("SMTP_HOST")
    smtp_port = int(os.environ.get("SMTP_PORT", "587"))
    smtp_user = os.environ.get("SMTP_USER")
    smtp_pass = os.environ.get("SMTP_PASS")
    mail_from = os.environ.get("MAIL_FROM")
    mail_to = os.environ.get("MAIL_TO")

    if not all([smtp_host, smtp_port, smtp_user, smtp_pass, mail_from, mail_to]):
        raise EnvironmentError("SMTP ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ê°€ ì¶©ë¶„íˆ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    msg = MIMEMultipart("alternative")
    msg["Subject"] = f"Daily Portfolio Report - {datetime.now().strftime('%Y-%m-%d')}"
    msg["From"] = mail_from
    msg["To"] = mail_to

    part_html = MIMEText(html_body, "html")
    msg.attach(part_html)

    with smtplib.SMTP(smtp_host, smtp_port) as server:
        server.starttls()
        server.login(smtp_user, smtp_pass)
        server.sendmail(mail_from, [mail_to], msg.as_string())


# =========================
# ë©”ì¸ ì‹¤í–‰ ë¡œì§
# =========================

def main():
    gsheet_id = os.environ.get("GSHEET_ID")
    if not gsheet_id:
        raise EnvironmentError("í™˜ê²½ë³€ìˆ˜ GSHEET_ID ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")

    sheet = open_gsheet(gsheet_id)

    df_holdings = load_holdings_from_gsheet(sheet)
    settings_df = load_settings_from_gsheet(sheet)

    fx_usdcad = get_fx_rate_usdcad()

    html = build_html_report(df_holdings, settings_df, fx_usdcad)
    send_email_report(html)


if __name__ == "__main__":
    main()
